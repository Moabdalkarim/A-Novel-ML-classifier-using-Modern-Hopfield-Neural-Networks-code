{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "!git clone https://github.com/Moabdalkarim/A-Novel-ML-classifier-using-Modern-Hopfield-Neural-Networks-code.git\n",
        "%cd /content/A-Novel-ML-classifier-using-Modern-Hopfield-Neural-Networks-code"
      ],
      "metadata": {
        "id": "bPxB5S09t2uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "from Hopfield_classifier.classifier import Hopfield_Classifier\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# load dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize\n",
        "x_train=(x_train/127)-1\n",
        "x_test=(x_test/127)-1\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "x_test = np.array(x_test)\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "# print sizes\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
        "print(\"min:\",x_train.min(),\"mean:\",x_train.mean(),\"max:\",x_train.max())\n",
        "\n",
        "\n",
        "\n",
        "######################################################## Train the HNN models\n",
        "\n",
        "\n",
        "# train\n",
        "# Initialize the Hopfield Network\n",
        "model_HNN = Hopfield_Classifier()\n",
        "model_HNN_WC = Hopfield_Classifier(w_compress=0.5)\n",
        "model_HNN_PCA = Hopfield_Classifier(PCA=0.9)\n",
        "\n",
        "model_HNN.fit(x_train,y_train,silent=False)\n",
        "model_HNN_WC.fit(x_train,y_train,silent=False)\n",
        "model_HNN_PCA.fit(x_train,y_train,silent=False)\n",
        "\n",
        "\n",
        "\n",
        "######################################################## Training set prediction\n",
        "\n",
        "\n",
        "# predict HNN\n",
        "print(\"\\n================ Train set HNN ================\\n\")\n",
        "y_pred = model_HNN.predict (x_train,patch_size=3000,silent=False)\n",
        "print(\"accuracy: \",accuracy_score(np.array(y_train), np.array(y_pred)),'\\n')\n",
        "print(classification_report(np.array(y_train), np.array(y_pred)))\n",
        "\n",
        "# predict HNN_WC\n",
        "print(\"\\n================ Train set HNN_WC ================\\n\")\n",
        "y_pred = model_HNN_WC.predict (x_train,patch_size=3000,silent=False)\n",
        "print(\"accuracy: \",accuracy_score(np.array(y_train), np.array(y_pred)),'\\n')\n",
        "print(classification_report(np.array(y_train), np.array(y_pred)))\n",
        "\n",
        "# predict HNN_PCA\n",
        "print(\"\\n================ Train set HNN_PCA ================\\n\")\n",
        "y_pred = model_HNN_PCA.predict (x_train,patch_size=3000,silent=False)\n",
        "print(\"accuracy: \",accuracy_score(np.array(y_train), np.array(y_pred)),'\\n')\n",
        "print(classification_report(np.array(y_train), np.array(y_pred)))\n",
        "\n",
        "\n",
        "\n",
        "######################################################## Test set prediction\n",
        "\n",
        "\n",
        "# predict HNN\n",
        "print(\"\\n================ Test set HNN ================\\n\")\n",
        "y_pred = model_HNN.predict (x_test,patch_size=3000,silent=False)\n",
        "print(\"accuracy: \",accuracy_score(np.array(y_test), np.array(y_pred)),'\\n')\n",
        "print(classification_report(np.array(y_test), np.array(y_pred)))\n",
        "\n",
        "# predict HNN_WC\n",
        "print(\"\\n================ Test set HNN_WC ================\\n\")\n",
        "y_pred = model_HNN_WC.predict (x_test,patch_size=3000,silent=False)\n",
        "print(\"accuracy: \",accuracy_score(np.array(y_test), np.array(y_pred)),'\\n')\n",
        "print(classification_report(np.array(y_test), np.array(y_pred)))\n",
        "\n",
        "# predict HNN_PCA\n",
        "print(\"\\n================ Test set HNN_PCA ================\\n\")\n",
        "y_pred = model_HNN_PCA.predict (x_test,patch_size=3000,silent=False)\n",
        "print(\"accuracy: \",accuracy_score(np.array(y_test), np.array(y_pred)),'\\n')\n",
        "print(classification_report(np.array(y_test), np.array(y_pred)))"
      ],
      "metadata": {
        "id": "omfuJRszhC_q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}